{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32Be4BXthRMH",
      "metadata": {
        "id": "32Be4BXthRMH"
      },
      "source": [
        "##Working GAN 26X26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mdR5MsUEhexH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdR5MsUEhexH",
        "outputId": "707d01f4-3d7f-4256-aef0-8d7c6ed7af14"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JDNEDOmjhgtl",
      "metadata": {
        "id": "JDNEDOmjhgtl"
      },
      "outputs": [],
      "source": [
        "def spectral_norm_conv(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "    return nn.utils.spectral_norm(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                 stride=stride, padding=padding, bias=bias)\n",
        "    )\n",
        "\n",
        "def spectral_norm_linear(in_features, out_features, bias=True):\n",
        "    return nn.utils.spectral_norm(\n",
        "        nn.Linear(in_features, out_features, bias=bias)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJAPavAAnvkm",
      "metadata": {
        "id": "UJAPavAAnvkm"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Circle Layer\n",
        "# ------------------------------\n",
        "class CircleConstraintLayer(nn.Module):\n",
        "    def __init__(self, image_size=26):\n",
        "        super().__init__()\n",
        "        # Create circle mask parameters\n",
        "        self.image_size = image_size\n",
        "        self.register_buffer('circle_mask_inside', None)\n",
        "        self.register_buffer('circle_mask_outside', None)\n",
        "\n",
        "    def create_masks(self, device):\n",
        "        # Create masks only once\n",
        "        center = self.image_size / 2 - 0.5\n",
        "        radius = self.image_size / 2\n",
        "\n",
        "        y, x_coords = torch.meshgrid(\n",
        "            torch.arange(self.image_size, device=device),\n",
        "            torch.arange(self.image_size, device=device)\n",
        "        )\n",
        "\n",
        "        distance = torch.sqrt((x_coords - center)**2 + (y - center)**2)\n",
        "        inside_mask = (distance <= radius).float()\n",
        "        outside_mask = 1.0 - inside_mask\n",
        "\n",
        "        return inside_mask.unsqueeze(0).unsqueeze(0), outside_mask.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Create masks if not created yet\n",
        "        if self.circle_mask_inside is None or self.circle_mask_inside.device != x.device:\n",
        "            inside_mask, outside_mask = self.create_masks(x.device)\n",
        "            self.circle_mask_inside = inside_mask\n",
        "            self.circle_mask_outside = outside_mask\n",
        "\n",
        "        # Apply mask to encourage proper values in each region\n",
        "        batch_size = x.size(0)\n",
        "        inside_mask = self.circle_mask_inside.expand(batch_size, -1, -1, -1)\n",
        "        outside_mask = self.circle_mask_outside.expand(batch_size, -1, -1, -1)\n",
        "\n",
        "        # Push values to be >= 0 inside the circle\n",
        "        x = torch.where(\n",
        "            (x < 0) & (inside_mask > 0.5),\n",
        "            torch.zeros_like(x),  # Replace with 0 if negative inside circle\n",
        "            x\n",
        "        )\n",
        "\n",
        "        # Don't have this as it makes it too perfect a circle\n",
        "        '''# Push values to be -1 outside the circle\n",
        "        x = torch.where(\n",
        "            (x > -1) & (outside_mask > 0.5),\n",
        "            -torch.ones_like(x),  # Replace with -1 if not -1 outside circle\n",
        "            x\n",
        "        )'''\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SneZFM_ThkQm",
      "metadata": {
        "id": "SneZFM_ThkQm"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Quantize to Ternary\n",
        "# ------------------------------\n",
        "class QuantizeToTernary(nn.Module):\n",
        "    \"\"\"Optimized ternary quantization using PyTorch vectorized ops\"\"\"\n",
        "    def __init__(self, threshold=0.33):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Vectorized ternary quantization with STE\n",
        "        quantized = torch.where(\n",
        "            torch.abs(inputs) > self.threshold,\n",
        "            torch.sign(inputs),\n",
        "            torch.zeros_like(inputs)\n",
        "        )\n",
        "        return inputs + (quantized - inputs).detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58qTTFXGhmsT",
      "metadata": {
        "id": "58qTTFXGhmsT"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Feature Extractor\n",
        "# ------------------------------\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.leaky_relu1 = nn.LeakyReLU(0.2)\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.instance_norm = nn.InstanceNorm2d(64)\n",
        "        self.leaky_relu2 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu1(self.conv1(x))\n",
        "        x = self.max_pool(x)  # 13x13\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.instance_norm(x)\n",
        "        x = self.leaky_relu2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0mVXQrD_hotI",
      "metadata": {
        "id": "0mVXQrD_hotI"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Generator\n",
        "# ------------------------------\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.ConvTranspose2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.instance_norm1 = nn.InstanceNorm2d(channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.ConvTranspose2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.instance_norm2 = nn.InstanceNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.instance_norm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.instance_norm2(x)\n",
        "        return x + shortcut\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=256):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.fc = nn.Linear(latent_dim, 13*13*256)\n",
        "\n",
        "        self.res_block = ResBlock(256)\n",
        "\n",
        "        self.conv_transpose1 = nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.instance_norm = nn.InstanceNorm2d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.conv_transpose2 = nn.ConvTranspose2d(128, 1, kernel_size=5, padding=2)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.quantizer = QuantizeToTernary(threshold=0.33)\n",
        "        self.circle_constraint = CircleConstraintLayer()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 256, 13, 13)\n",
        "\n",
        "        x = self.res_block(x)\n",
        "\n",
        "        x = self.conv_transpose1(x)\n",
        "        x = self.instance_norm(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_transpose2(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.quantizer(x)\n",
        "\n",
        "        ## Implement this but just don't apply this, based on the resuts we can modify it.\n",
        "        #x = self.circle_constraint(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "erEhlZ_YhvVY",
      "metadata": {
        "id": "erEhlZ_YhvVY"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Discriminator/Critic\n",
        "# ------------------------------\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First spectral normalized conv layer\n",
        "        self.conv1 = spectral_norm_conv(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu1 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Second spectral normalized conv layer\n",
        "        self.conv2 = spectral_norm_conv(64, 128, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu2 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Flattening happens in forward()\n",
        "\n",
        "        # Final spectral normalized linear layer\n",
        "        # Calculate the input size for the linear layer\n",
        "        # After two stride-2 convolutions on a 26x26 input, we get 7x7 (ceiling division)\n",
        "        self.linear = spectral_norm_linear(128 * 7 * 7, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu1(self.conv1(x))\n",
        "        x = self.leaky_relu2(self.conv2(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BYJIF7Nlhz0G",
      "metadata": {
        "id": "BYJIF7Nlhz0G"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Data Loading\n",
        "# ------------------------------\n",
        "class WaferDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.data[idx])\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        data = np.array(pickle.load(f))\n",
        "\n",
        "    # Ensure data is in the right format (26x26x1) and normalized to [-1, 1]\n",
        "    if isinstance(data, np.ndarray):\n",
        "        # If already a numpy array, reshape if needed\n",
        "        if len(data.shape) == 3:  # [num_samples, height, width]\n",
        "            data = np.expand_dims(data, axis=1)  # Add channel dimension (PyTorch uses NCHW format)\n",
        "        elif len(data.shape) == 2:  # [num_samples, flattened_dim]\n",
        "            data = data.reshape(-1, 1, 26, 26)  # Reshape to NCHW format\n",
        "        elif len(data.shape) == 4 and data.shape[3] == 1:  # NHWC format from TensorFlow\n",
        "            data = np.transpose(data, (0, 3, 1, 2))  # Convert to NCHW format\n",
        "    else:\n",
        "        raise ValueError(\"Expected numpy array in the pickle file\")\n",
        "\n",
        "    # Verify the shape is correct (note: PyTorch uses NCHW format)\n",
        "    assert data.shape[1:] == (1, 26, 26), f\"Expected shape (*, 1, 26, 26), got {data.shape}\"\n",
        "\n",
        "    # Verify data range is [-1, 1]\n",
        "    data_min, data_max = np.min(data), np.max(data)\n",
        "    if not (np.isclose(data_min, -1) and np.isclose(data_max, 1)):\n",
        "        print(f\"Warning: Data range is [{data_min}, {data_max}], normalizing to [-1, 1]\")\n",
        "        data = 2 * (data - data_min) / (data_max - data_min) - 1\n",
        "\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AZObiW74h61O",
      "metadata": {
        "id": "AZObiW74h61O"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Gradient Penalty\n",
        "# ------------------------------\n",
        "def gradient_penalty(critic, real_images, fake_images):\n",
        "    batch_size = real_images.size(0)\n",
        "\n",
        "    # Generate random interpolation factors\n",
        "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
        "\n",
        "    # Create interpolated images\n",
        "    interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
        "    interpolated.requires_grad_(True)\n",
        "\n",
        "    # Get critic scores for interpolated images\n",
        "    pred = critic(interpolated)\n",
        "\n",
        "    # Calculate gradients w.r.t. interpolated images\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=pred,\n",
        "        inputs=interpolated,\n",
        "        grad_outputs=torch.ones_like(pred, device=device),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    # Compute gradient norms\n",
        "    gradients = gradients.view(batch_size, -1)\n",
        "    grad_norms = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "\n",
        "    # Return gradient penalty (mean squared deviation from 1)\n",
        "    return torch.mean((grad_norms - 1.0) ** 2)\n",
        "\n",
        "# ------------------------------\n",
        "# Perceptual Loss\n",
        "# ------------------------------\n",
        "def perceptual_loss(feature_extractor, real, fake):\n",
        "    real_features = feature_extractor(real)\n",
        "    fake_features = feature_extractor(fake)\n",
        "    return torch.mean((real_features - fake_features) ** 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ln4tJygOlgAJ",
      "metadata": {
        "id": "ln4tJygOlgAJ"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Circle Penalty\n",
        "# ------------------------------\n",
        "def circle_constraint_loss(generated_images, image_size=26, weight=0.5):\n",
        "    \"\"\"\n",
        "    Creates a loss that penalizes:\n",
        "    - Values of -1 inside an inscribed circle (loss of 1 per pixel)\n",
        "    - Values of 0 or 1 outside the inscribed circle (loss of 1 per pixel)\n",
        "\n",
        "    Args:\n",
        "        generated_images: Tensor of shape [batch_size, 1, height, width]\n",
        "        image_size: Size of the square image (assuming height=width)\n",
        "        weight: Weight factor for this loss component\n",
        "\n",
        "    Returns:\n",
        "        Weighted loss tensor\n",
        "    \"\"\"\n",
        "    batch_size = generated_images.size(0)\n",
        "\n",
        "    # Create a circular mask\n",
        "    center = image_size / 2 - 0.5  # Center coordinates (0-indexed)\n",
        "    radius = image_size / 2        # Radius of inscribed circle\n",
        "\n",
        "    y, x = torch.meshgrid(\n",
        "        torch.arange(image_size, device=generated_images.device),\n",
        "        torch.arange(image_size, device=generated_images.device)\n",
        "    )\n",
        "\n",
        "    # Calculate distance from center\n",
        "    distance = torch.sqrt((x - center)**2 + (y - center)**2)\n",
        "\n",
        "    # Create masks for inside and outside the circle\n",
        "    inside_mask = (distance <= radius).float().unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, H, W]\n",
        "    outside_mask = 1 - inside_mask  # Inverse of inside mask\n",
        "\n",
        "    # Repeat masks for batch size\n",
        "    inside_mask = inside_mask.repeat(batch_size, 1, 1, 1)\n",
        "    outside_mask = outside_mask.repeat(batch_size, 1, 1, 1)\n",
        "\n",
        "    # Calculate penalties:\n",
        "    # 1. Penalty for -1 values inside the circle (should be 0 or 1)\n",
        "    inside_penalty = inside_mask * (generated_images == -1).float()\n",
        "\n",
        "    # 2. Penalty for 0 or 1 values outside the circle (should be -1)\n",
        "    outside_penalty = outside_mask * (generated_images != -1).float()\n",
        "\n",
        "    # Sum all penalties\n",
        "    total_penalty = inside_penalty.sum() * 2 + outside_penalty.sum()\n",
        "\n",
        "    # Average per image in batch\n",
        "    avg_penalty = total_penalty / batch_size\n",
        "\n",
        "    # Apply weight\n",
        "    return weight * avg_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0cffdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_training_losses(gen_losses, critic_losses_real, critic_losses_fake, smoothing_factor=128):\n",
        "    \"\"\"\n",
        "    Plot the training losses over epochs with smoothing.\n",
        "    \n",
        "    Args:\n",
        "        gen_losses (list): Generator losses for each epoch\n",
        "        critic_losses_real (list): Critic losses for real images for each epoch\n",
        "        critic_losses_fake (list): Critic losses for fake images for each epoch\n",
        "        smoothing_factor (int): Window size for moving average smoothing\n",
        "    \"\"\"\n",
        "    epochs = len(gen_losses)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # Apply smoothing using moving average\n",
        "    def smooth(y, box_pts):\n",
        "        box = np.ones(box_pts) / box_pts\n",
        "        y_smooth = np.convolve(y, box, mode='same')\n",
        "        # Fix the edges where the window extends beyond data\n",
        "        for i in range(box_pts//2):\n",
        "            if i < len(y):\n",
        "                # Left edge\n",
        "                y_smooth[i] = np.mean(y[:i*2+1])\n",
        "                # Right edge\n",
        "                if i < min(box_pts//2, len(y)):\n",
        "                    y_smooth[-(i+1)] = np.mean(y[-(i*2+1):])\n",
        "        return y_smooth\n",
        "    \n",
        "    # Only apply smoothing if we have enough data\n",
        "    if epochs >= smoothing_factor:\n",
        "        gen_smooth = smooth(gen_losses, smoothing_factor)\n",
        "        critic_real_smooth = smooth(critic_losses_real, smoothing_factor)\n",
        "        critic_fake_smooth = smooth(critic_losses_fake, smoothing_factor)\n",
        "    else:\n",
        "        gen_smooth = gen_losses\n",
        "        critic_real_smooth = critic_losses_real\n",
        "        critic_fake_smooth = critic_losses_fake\n",
        "    \n",
        "    # Create x-axis for epochs\n",
        "    x = np.arange(1, epochs + 1)\n",
        "    \n",
        "    # Plot the data\n",
        "    plt.plot(x, gen_smooth, label='Generator Loss (smoothed)', color='blue', linewidth=2)\n",
        "    plt.plot(x, critic_real_smooth, label='Critic Loss - Real (smoothed)', color='green', linewidth=2)\n",
        "    plt.plot(x, critic_fake_smooth, label='Critic Loss - Fake (smoothed)', color='red', linewidth=2)\n",
        "    \n",
        "    # Add original data as light dotted lines for reference\n",
        "    plt.plot(x, gen_losses, label='Generator Loss (raw)', color='blue', alpha=0.3, linestyle='dotted')\n",
        "    plt.plot(x, critic_losses_real, label='Critic Loss - Real (raw)', color='green', alpha=0.3, linestyle='dotted')\n",
        "    plt.plot(x, critic_losses_fake, label='Critic Loss - Fake (raw)', color='red', alpha=0.3, linestyle='dotted')\n",
        "    \n",
        "    # Add labels and legend\n",
        "    plt.xlabel('Epoch', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.title('WGAN Training Losses Over Time', fontsize=16)\n",
        "    plt.legend(loc='best', fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add horizontal line at y=0 for reference\n",
        "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    \n",
        "    \n",
        "    # Show the figure\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rP0dscBXhYxq",
      "metadata": {
        "id": "rP0dscBXhYxq"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Training Functions\n",
        "# ------------------------------\n",
        "def train_critic(critic, generator, critic_optimizer, real_images, latent_dim, GP_WEIGHT):\n",
        "    batch_size = real_images.size(0)\n",
        "\n",
        "    # Zero gradients\n",
        "    critic_optimizer.zero_grad()\n",
        "\n",
        "    # Generate latent vectors\n",
        "    noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "\n",
        "    # Generate fake images\n",
        "    fake_images = generator(noise)\n",
        "\n",
        "    # Get critic scores\n",
        "    real_scores = critic(real_images)\n",
        "    fake_scores = critic(fake_images.detach())  # Detach to avoid training generator\n",
        "\n",
        "    # Calculate Wasserstein loss\n",
        "    critic_loss = torch.mean(fake_scores) - torch.mean(real_scores)\n",
        "\n",
        "    # Add gradient penalty\n",
        "    gp = gradient_penalty(critic, real_images, fake_images.detach())\n",
        "    total_critic_loss = critic_loss + GP_WEIGHT * gp\n",
        "\n",
        "    # Update critic weights\n",
        "    total_critic_loss.backward()\n",
        "    critic_optimizer.step()\n",
        "\n",
        "    return total_critic_loss.item()\n",
        "\n",
        "def train_generator(generator, critic, feature_extractor, generator_optimizer, batch_size, latent_dim):\n",
        "    # Zero gradients\n",
        "    generator_optimizer.zero_grad()\n",
        "\n",
        "    # Generate latent vectors\n",
        "    noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "\n",
        "    # Generate fake images\n",
        "    fake_images = generator(noise)\n",
        "\n",
        "    # Get critic scores for fake images\n",
        "    fake_scores = critic(fake_images)\n",
        "\n",
        "    # Calculate adversarial loss (negative of critic score)\n",
        "    adv_loss = -torch.mean(fake_scores)\n",
        "\n",
        "    # Calculate perceptual loss if feature extractor is provided\n",
        "    if feature_extractor is not None:\n",
        "        # Since we don't have real images here, we'll skip the perceptual loss\n",
        "        # This will be calculated in the main training loop with real images\n",
        "        perc_loss = torch.tensor(0.0, device=device)\n",
        "    else:\n",
        "        perc_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "    # Calculate circle constraint loss\n",
        "    ## Implement this but let the weight be zero.\n",
        "    circle_loss = circle_constraint_loss(fake_images, image_size=26, weight=0)\n",
        "\n",
        "    # Final generator loss\n",
        "    # Do an implementation where the weight gradually grows as the epochs increase.\n",
        "    total_gen_loss = adv_loss + perc_loss + circle_loss\n",
        "\n",
        "\n",
        "    # Update generator weights\n",
        "    total_gen_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    return total_gen_loss.item()\n",
        "\n",
        "# ------------------------------\n",
        "# Generate and Save Images\n",
        "# ------------------------------\n",
        "def generate_and_save_images(model, epoch, test_input, checkpoint_dir):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        predictions = model(test_input)\n",
        "\n",
        "    # Convert to numpy for plotting\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(min(16, test_input.size(0))):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "\n",
        "        # Get the generated wafer map and scale to [0,1]\n",
        "        wafer_map = (predictions[i, 0, :, :] + 1) / 2.0  # Assuming [-1,1] input\n",
        "\n",
        "        # Plot with BRG colormap\n",
        "        plt.imshow(wafer_map, cmap='brg', vmin=0, vmax=1)\n",
        "\n",
        "        # Add title\n",
        "        plt.title(f\"Defect Map {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Save to checkpoint directory\n",
        "    save_path = os.path.join(checkpoint_dir, f'epoch_{epoch:04d}.png')\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    # Display the figure\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    model.train()  # Set back to training mode\n",
        "\n",
        "# ------------------------------\n",
        "# Create GIF of Progress\n",
        "# ------------------------------\n",
        "def create_progress_gif(image_dir):\n",
        "    try:\n",
        "        import imageio\n",
        "        filenames = sorted([f for f in os.listdir(image_dir) if f.startswith('epoch_')])\n",
        "\n",
        "        with imageio.get_writer('training_progress.gif', mode='I') as writer:\n",
        "            for filename in filenames:\n",
        "                image = imageio.imread(os.path.join(image_dir, filename))\n",
        "                writer.append_data(image)\n",
        "\n",
        "        print(\"GIF created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create GIF: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Main Training Loop\n",
        "# ------------------------------\n",
        "def train(dataloader, generator, critic, feature_extractor, generator_optimizer,\n",
        "          critic_optimizer, epochs, latent_dim, checkpoint_dir, save_interval, GP_WEIGHT):\n",
        "\n",
        "    # Create fixed noise vector for visualization\n",
        "    fixed_noise = torch.randn(16, latent_dim, device=device)\n",
        "\n",
        "    # Track losses for plotting\n",
        "    gen_losses = []\n",
        "    critic_losses = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        total_gen_loss = 0\n",
        "        total_critic_loss = 0\n",
        "        batches = 0\n",
        "\n",
        "        # Train on batches\n",
        "        for batch_images in dataloader:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_size = batch_images.size(0)\n",
        "\n",
        "            # Train critic multiple times\n",
        "            for _ in range(5):\n",
        "                c_loss = train_critic(critic, generator, critic_optimizer, batch_images, latent_dim, GP_WEIGHT)\n",
        "                total_critic_loss += c_loss\n",
        "\n",
        "            # Train generator\n",
        "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            # Calculate perceptual loss if feature extractor is provided\n",
        "            if feature_extractor is not None:\n",
        "                perc_loss = 0.1 * perceptual_loss(feature_extractor, batch_images, fake_images)\n",
        "            else:\n",
        "                perc_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # Get fake scores from critic\n",
        "            fake_scores = critic(fake_images)\n",
        "\n",
        "            # Calculate generator loss\n",
        "            adv_loss = -torch.mean(fake_scores)\n",
        "            total_gen_loss_tensor = adv_loss + perc_loss\n",
        "\n",
        "            # Update generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            total_gen_loss_tensor.backward()\n",
        "            generator_optimizer.step()\n",
        "\n",
        "            total_gen_loss += total_gen_loss_tensor.item()\n",
        "\n",
        "            batches += 1\n",
        "\n",
        "            # Print occasional batch updates\n",
        "            if batches % 20 == 0:\n",
        "                print(f\"  Batch {batches}, G Loss: {total_gen_loss_tensor.item():.4f}, C Loss: {c_loss:.4f}\")\n",
        "\n",
        "        # Calculate average losses for the epoch\n",
        "        avg_gen_loss = total_gen_loss / batches if batches > 0 else float('nan')\n",
        "        avg_critic_loss = total_critic_loss / (batches * 5) if batches > 0 else float('nan')\n",
        "\n",
        "        gen_losses.append(avg_gen_loss)\n",
        "        critic_losses.append(avg_critic_loss)\n",
        "\n",
        "        # Print status\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Gen Loss: {avg_gen_loss:.4f}, '\n",
        "              f'Critic Loss: {avg_critic_loss:.4f}, Time: {epoch_time:.2f}s')\n",
        "\n",
        "        # Generate/save/show images EVERY epoch\n",
        "        if (epoch % 5 == 0):\n",
        "            plot_training_losses(gen_losses, critic_losses_real, critic_losses_fake, smoothing_factor=min(128, len(gen_losses)))\n",
        "            generate_and_save_images(generator, epoch + 1, fixed_noise, checkpoint_dir)\n",
        "          \n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            torch.save({\n",
        "                'generator_state_dict': generator.state_dict(),\n",
        "                'critic_state_dict': critic.state_dict(),\n",
        "                'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n",
        "                'critic_optimizer_state_dict': critic_optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'gen_loss': avg_gen_loss,\n",
        "                'critic_loss': avg_critic_loss\n",
        "            }, os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"Training completed in {total_time:.2f} seconds\")\n",
        "\n",
        "    # Create GIF showing training progress\n",
        "    create_progress_gif(checkpoint_dir)\n",
        "\n",
        "    # Save final models\n",
        "    torch.save(generator, os.path.join(checkpoint_dir, 'Scratch_generator_final.pt'))\n",
        "    torch.save(critic, os.path.join(checkpoint_dir, 'Scratch_critic_final.pt'))\n",
        "\n",
        "# ------------------------------\n",
        "# Generate Images from Trained Model\n",
        "# ------------------------------\n",
        "def generate_samples(generator, num_images, latent_dim, output_dir):\n",
        "    \"\"\"Generate a specific number of images\"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    generator.eval()\n",
        "\n",
        "    # Generate in batches to avoid memory issues\n",
        "    batch_size = 16\n",
        "    all_images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, num_images, batch_size):\n",
        "            batch_count = min(batch_size, num_images - i)\n",
        "            noise = torch.randn(batch_count, latent_dim, device=device)\n",
        "            images = generator(noise)\n",
        "            all_images.append(images.cpu())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    all_images = torch.cat(all_images, dim=0)\n",
        "\n",
        "    # Plot a grid of generated images\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(min(25, num_images)):\n",
        "        plt.subplot(5, 5, i+1)\n",
        "        plt.imshow(all_images[i, 0, :, :], cmap='brg')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/generated_sample_grid.png')\n",
        "    plt.show()\n",
        "\n",
        "    return all_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_LtE94Ncuy_1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "_LtE94Ncuy_1",
        "outputId": "c6bff3dd-71b6-4778-a1e4-1e9c8fce8e51"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------\n",
        "# Main Function\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Parameters\n",
        "    latent_dim = 256\n",
        "    BATCH_SIZE = 64\n",
        "    GP_WEIGHT = 10.0\n",
        "    EPOCHS = 100\n",
        "    save_interval = 5\n",
        "    checkpoint_dir = '/content/Donut 26X26'\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(\"/content/Donut_output.pkl\")  # Update with your path\n",
        "    print(f\"Dataset loaded with shape: {dataset.shape}\")\n",
        "\n",
        "    # Create data loader\n",
        "    wafer_dataset = WaferDataset(dataset)\n",
        "    dataloader = DataLoader(wafer_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "    # Initialize models\n",
        "    feature_extractor = FeatureExtractor().to(device)\n",
        "    feature_extractor.eval()  # Set to evaluation mode since it's not trained\n",
        "\n",
        "    generator = Generator(latent_dim=latent_dim).to(device)\n",
        "    critic = Critic().to(device)\n",
        "\n",
        "    # Initialize optimizers\n",
        "    generator_optimizer = optim.RMSprop(generator.parameters(), lr=5e-5)\n",
        "    critic_optimizer = optim.RMSprop(critic.parameters(), lr=5e-5)\n",
        "\n",
        "    # Print model summaries\n",
        "    print(\"\\nGenerator architecture:\")\n",
        "    print(generator)\n",
        "\n",
        "    print(\"\\nCritic architecture:\")\n",
        "    print(critic)\n",
        "\n",
        "    print(\"\\nFeature Extractor architecture:\")\n",
        "    print(feature_extractor)\n",
        "\n",
        "    # Start training\n",
        "    print(\"\\nStarting training...\")\n",
        "    train(dataloader, generator, critic, feature_extractor, generator_optimizer,\n",
        "          critic_optimizer, EPOCHS, latent_dim, checkpoint_dir, save_interval, GP_WEIGHT)\n",
        "\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "    # Generate samples\n",
        "    print(\"Generating samples...\")\n",
        "    generated_samples = generate_samples(generator, 100, latent_dim, 'generated_samples')\n",
        "\n",
        "    # Save to pickle file\n",
        "    with open('./generated_data.pkl', 'wb') as f:\n",
        "        pickle.dump(generated_samples.numpy(), f)\n",
        "\n",
        "    print(\"Samples generated and saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_T_3RC5jG5A6",
      "metadata": {
        "id": "_T_3RC5jG5A6"
      },
      "source": [
        "## WGAN 128X128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "awR0DuY5G8_5",
      "metadata": {
        "id": "awR0DuY5G8_5"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Generator\n",
        "# ------------------------------\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.ConvTranspose2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.instance_norm1 = nn.InstanceNorm2d(channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.ConvTranspose2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.instance_norm2 = nn.InstanceNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.instance_norm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.instance_norm2(x)\n",
        "        return x + shortcut\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=256):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Increased initial dense layer size (16x16x512 instead of 13x13x256)\n",
        "        self.fc = nn.Linear(latent_dim, 16*16*512)\n",
        "\n",
        "        # Multiple ResBlocks at different resolutions\n",
        "        self.res_block1 = ResBlock(512)\n",
        "        self.res_block2 = ResBlock(512)\n",
        "\n",
        "        # Upsampling path: 16x16 → 32x32 → 64x64 → 128x128\n",
        "        # First upsampling: 16x16 → 32x32\n",
        "        self.conv_transpose1 = nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.instance_norm1 = nn.InstanceNorm2d(256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Second upsampling: 32x32 → 64x64\n",
        "        self.conv_transpose2 = nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.instance_norm2 = nn.InstanceNorm2d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Third upsampling: 64x64 → 128x128\n",
        "        self.conv_transpose3 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.instance_norm3 = nn.InstanceNorm2d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # Final output layer\n",
        "        self.conv_transpose4 = nn.ConvTranspose2d(64, 1, kernel_size=5, padding=2)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.quantizer = QuantizeToTernary(threshold=0.33)\n",
        "        self.circle_constraint = CircleConstraintLayer(image_size=128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 512, 16, 16)\n",
        "\n",
        "        # Apply ResBlocks\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "\n",
        "        # First upsampling: 16x16 → 32x32\n",
        "        x = self.conv_transpose1(x)\n",
        "        x = self.instance_norm1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        # Second upsampling: 32x32 → 64x64\n",
        "        x = self.conv_transpose2(x)\n",
        "        x = self.instance_norm2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        # Third upsampling: 64x64 → 128x128\n",
        "        x = self.conv_transpose3(x)\n",
        "        x = self.instance_norm3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        # Final output layer\n",
        "        x = self.conv_transpose4(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.quantizer(x)\n",
        "\n",
        "        # Uncomment if you want to apply the circle constraint\n",
        "        # x = self.circle_constraint(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LGoB0hCkHZV1",
      "metadata": {
        "id": "LGoB0hCkHZV1"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Discriminator/Critic\n",
        "# ------------------------------\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional path: 128x128 → 64x64 → 32x32 → 16x16 → 8x8 → 4x4\n",
        "        # First layer: 128x128 → 64x64\n",
        "        self.conv1 = spectral_norm_conv(1, 32, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu1 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Second layer: 64x64 → 32x32\n",
        "        self.conv2 = spectral_norm_conv(32, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu2 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Third layer: 32x32 → 16x16\n",
        "        self.conv3 = spectral_norm_conv(64, 128, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu3 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Fourth layer: 16x16 → 8x8\n",
        "        self.conv4 = spectral_norm_conv(128, 256, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu4 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Fifth layer: 8x8 → 4x4\n",
        "        self.conv5 = spectral_norm_conv(256, 512, kernel_size=5, stride=2, padding=2)\n",
        "        self.leaky_relu5 = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # Final linear layer with adjusted input size (512 * 4 * 4)\n",
        "        self.linear = spectral_norm_linear(512 * 4 * 4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu1(self.conv1(x))\n",
        "        x = self.leaky_relu2(self.conv2(x))\n",
        "        x = self.leaky_relu3(self.conv3(x))\n",
        "        x = self.leaky_relu4(self.conv4(x))\n",
        "        x = self.leaky_relu5(self.conv5(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PdTQbcQ2HbN7",
      "metadata": {
        "id": "PdTQbcQ2HbN7"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Feature Extractor (Optional Modification)\n",
        "# ------------------------------\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Modified for 128x128 input\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.leaky_relu1 = nn.LeakyReLU(0.2)\n",
        "        self.max_pool1 = nn.MaxPool2d(2)  # 64x64\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.instance_norm1 = nn.InstanceNorm2d(64)\n",
        "        self.leaky_relu2 = nn.LeakyReLU(0.2)\n",
        "        self.max_pool2 = nn.MaxPool2d(2)  # 32x32\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.instance_norm2 = nn.InstanceNorm2d(128)\n",
        "        self.leaky_relu3 = nn.LeakyReLU(0.2)\n",
        "        self.max_pool3 = nn.MaxPool2d(2)  # 16x16\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu1(self.conv1(x))\n",
        "        x = self.max_pool1(x)  # 64x64\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.instance_norm1(x)\n",
        "        x = self.leaky_relu2(x)\n",
        "        x = self.max_pool2(x)  # 32x32\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.instance_norm2(x)\n",
        "        x = self.leaky_relu3(x)\n",
        "        x = self.max_pool3(x)  # 16x16\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rVsImOSnIU3m",
      "metadata": {
        "id": "rVsImOSnIU3m"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Circle Layer\n",
        "# ------------------------------\n",
        "class CircleConstraintLayer(nn.Module):\n",
        "    def __init__(self, image_size=128):\n",
        "        super().__init__()\n",
        "        # Create circle mask parameters\n",
        "        self.image_size = image_size\n",
        "        self.register_buffer('circle_mask_inside', None)\n",
        "        self.register_buffer('circle_mask_outside', None)\n",
        "\n",
        "    def create_masks(self, device):\n",
        "        # Create masks only once\n",
        "        center = self.image_size / 2 - 0.5\n",
        "        radius = self.image_size / 2\n",
        "\n",
        "        y, x_coords = torch.meshgrid(\n",
        "            torch.arange(self.image_size, device=device),\n",
        "            torch.arange(self.image_size, device=device)\n",
        "        )\n",
        "\n",
        "        distance = torch.sqrt((x_coords - center)**2 + (y - center)**2)\n",
        "        inside_mask = (distance <= radius).float()\n",
        "        outside_mask = 1.0 - inside_mask\n",
        "\n",
        "        return inside_mask.unsqueeze(0).unsqueeze(0), outside_mask.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Create masks if not created yet\n",
        "        if self.circle_mask_inside is None or self.circle_mask_inside.device != x.device:\n",
        "            inside_mask, outside_mask = self.create_masks(x.device)\n",
        "            self.circle_mask_inside = inside_mask\n",
        "            self.circle_mask_outside = outside_mask\n",
        "\n",
        "        # Apply mask to encourage proper values in each region\n",
        "        batch_size = x.size(0)\n",
        "        inside_mask = self.circle_mask_inside.expand(batch_size, -1, -1, -1)\n",
        "        outside_mask = self.circle_mask_outside.expand(batch_size, -1, -1, -1)\n",
        "\n",
        "        # Push values to be >= 0 inside the circle\n",
        "        x = torch.where(\n",
        "            (x < 0) & (inside_mask > 0.5),\n",
        "            torch.zeros_like(x),  # Replace with 0 if negative inside circle\n",
        "            x\n",
        "        )\n",
        "\n",
        "        # Don't have this as it makes it too perfect a circle\n",
        "        '''# Push values to be -1 outside the circle\n",
        "        x = torch.where(\n",
        "            (x > -1) & (outside_mask > 0.5),\n",
        "            -torch.ones_like(x),  # Replace with -1 if not -1 outside circle\n",
        "            x\n",
        "        )'''\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sr0Qchf7IWdq",
      "metadata": {
        "id": "sr0Qchf7IWdq"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Circle Constraint Loss\n",
        "# ------------------------------\n",
        "def circle_constraint_loss(generated_images, image_size=128, weight=0.5):  # Changed default from 26 to 128\n",
        "    \"\"\"\n",
        "    Creates a loss that penalizes:\n",
        "    - Values of -1 inside an inscribed circle (loss of 1 per pixel)\n",
        "    - Values of 0 or 1 outside the inscribed circle (loss of 1 per pixel)\n",
        "    \"\"\"\n",
        "    # Rest of the implementation remains the same\n",
        "    # ...\n",
        "    batch_size = generated_images.size(0)\n",
        "\n",
        "    # Create a circular mask\n",
        "    center = image_size / 2 - 0.5  # Center coordinates (0-indexed)\n",
        "    radius = image_size / 2        # Radius of inscribed circle\n",
        "\n",
        "    y, x = torch.meshgrid(\n",
        "        torch.arange(image_size, device=generated_images.device),\n",
        "        torch.arange(image_size, device=generated_images.device)\n",
        "    )\n",
        "\n",
        "    # Calculate distance from center\n",
        "    distance = torch.sqrt((x - center)**2 + (y - center)**2)\n",
        "\n",
        "    # Create masks for inside and outside the circle\n",
        "    inside_mask = (distance <= radius).float().unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, H, W]\n",
        "    outside_mask = 1 - inside_mask  # Inverse of inside mask\n",
        "\n",
        "    # Repeat masks for batch size\n",
        "    inside_mask = inside_mask.repeat(batch_size, 1, 1, 1)\n",
        "    outside_mask = outside_mask.repeat(batch_size, 1, 1, 1)\n",
        "\n",
        "    # Calculate penalties:\n",
        "    # 1. Penalty for -1 values inside the circle (should be 0 or 1)\n",
        "    inside_penalty = inside_mask * (generated_images == -1).float()\n",
        "\n",
        "    # 2. Penalty for 0 or 1 values outside the circle (should be -1)\n",
        "    outside_penalty = outside_mask * (generated_images != -1).float()\n",
        "\n",
        "    # Sum all penalties\n",
        "    total_penalty = inside_penalty.sum() * 2 + outside_penalty.sum()\n",
        "\n",
        "    # Average per image in batch\n",
        "    avg_penalty = total_penalty / batch_size\n",
        "\n",
        "    # Apply weight\n",
        "    return weight * avg_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S6Qh7zMzHmrS",
      "metadata": {
        "id": "S6Qh7zMzHmrS"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Data Loading\n",
        "# ------------------------------\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        data = np.array(pickle.load(f))\n",
        "\n",
        "    # Ensure data is in the right format (128x128x1) and normalized to [-1, 1]\n",
        "    if isinstance(data, np.ndarray):\n",
        "        # If already a numpy array, reshape if needed\n",
        "        if len(data.shape) == 3:  # [num_samples, height, width]\n",
        "            data = np.expand_dims(data, axis=1)  # Add channel dimension (PyTorch uses NCHW format)\n",
        "        elif len(data.shape) == 2:  # [num_samples, flattened_dim]\n",
        "            data = data.reshape(-1, 1, 128, 128)  # Reshape to NCHW format\n",
        "        elif len(data.shape) == 4 and data.shape[3] == 1:  # NHWC format from TensorFlow\n",
        "            data = np.transpose(data, (0, 3, 1, 2))  # Convert to NCHW format\n",
        "    else:\n",
        "        raise ValueError(\"Expected numpy array in the pickle file\")\n",
        "\n",
        "    # Verify the shape is correct (note: PyTorch uses NCHW format)\n",
        "    assert data.shape[1:] == (1, 128, 128), f\"Expected shape (*, 1, 128, 128), got {data.shape}\"\n",
        "\n",
        "\n",
        "    # Verify data range is [-1, 1]\n",
        "    data_min, data_max = np.min(data), np.max(data)\n",
        "    if not (np.isclose(data_min, -1) and np.isclose(data_max, 1)):\n",
        "        print(f\"Warning: Data range is [{data_min}, {data_max}], normalizing to [-1, 1]\")\n",
        "        data = 2 * (data - data_min) / (data_max - data_min) - 1\n",
        "\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3exZKH0JWiA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d3exZKH0JWiA",
        "outputId": "b9f19d01-b401-4a95-924a-1f796c1e69a8"
      },
      "outputs": [],
      "source": [
        "def visualize_input_data(data_path, samples_per_row=5):\n",
        "    \"\"\"\n",
        "    Visualize input data samples using the same colormap as in training.\n",
        "    Displays 5 samples per row and as many rows as needed.\n",
        "\n",
        "    Args:\n",
        "        data_path: Path to the pickle file containing the data\n",
        "        samples_per_row: Number of samples to display per row (default: 5)\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    with open(data_path, \"rb\") as f:\n",
        "        data = np.array(pickle.load(f))\n",
        "\n",
        "    data = np.array(data)\n",
        "    print(\"Data shape after np.array:\", data.shape)\n",
        "    \n",
        "\n",
        "\n",
        "# Usage:\n",
        "visualize_input_data(\"/user/apurvara/Donut_augmented_data.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f8f6a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Main Training Loop with Loss Plotting\n",
        "# ------------------------------\n",
        "def train(dataloader, generator, critic, feature_extractor, generator_optimizer,\n",
        "          critic_optimizer, epochs, latent_dim, checkpoint_dir, save_interval, GP_WEIGHT):\n",
        "\n",
        "    # Create fixed noise vector for visualization\n",
        "    fixed_noise = torch.randn(16, latent_dim, device=device)\n",
        "\n",
        "    # Track losses for plotting\n",
        "    gen_losses = []\n",
        "    critic_losses_real = []\n",
        "    critic_losses_fake = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        total_gen_loss = 0\n",
        "        total_critic_loss_real = 0\n",
        "        total_critic_loss_fake = 0\n",
        "        batches = 0\n",
        "\n",
        "        # Train on batches\n",
        "        for batch_images in dataloader:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_size = batch_images.size(0)\n",
        "\n",
        "            # Train critic multiple times\n",
        "            for _ in range(5):\n",
        "                # Zero gradients\n",
        "                critic_optimizer.zero_grad()\n",
        "                \n",
        "                # Generate latent vectors and fake images\n",
        "                noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "                fake_images = generator(noise)\n",
        "                \n",
        "                # Get critic scores\n",
        "                real_scores = critic(batch_images)\n",
        "                fake_scores = critic(fake_images.detach())\n",
        "                \n",
        "                # Track separate losses\n",
        "                critic_loss_real = -torch.mean(real_scores)\n",
        "                critic_loss_fake = torch.mean(fake_scores)\n",
        "                \n",
        "                # Calculate Wasserstein loss\n",
        "                critic_loss = critic_loss_fake + critic_loss_real\n",
        "                \n",
        "                # Add gradient penalty\n",
        "                gp = gradient_penalty(critic, batch_images, fake_images.detach())\n",
        "                total_critic_loss = critic_loss + GP_WEIGHT * gp\n",
        "                \n",
        "                # Update critic weights\n",
        "                total_critic_loss.backward()\n",
        "                critic_optimizer.step()\n",
        "                \n",
        "                # Accumulate losses for averaging\n",
        "                total_critic_loss_real += critic_loss_real.item()\n",
        "                total_critic_loss_fake += critic_loss_fake.item()\n",
        "\n",
        "            # Train generator\n",
        "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            # Calculate perceptual loss if feature extractor is provided\n",
        "            if feature_extractor is not None:\n",
        "                perc_loss = 0.1 * perceptual_loss(feature_extractor, batch_images, fake_images)\n",
        "            else:\n",
        "                perc_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # Get fake scores from critic\n",
        "            fake_scores = critic(fake_images)\n",
        "\n",
        "            # Calculate generator loss\n",
        "            adv_loss = -torch.mean(fake_scores)\n",
        "            total_gen_loss_tensor = adv_loss + perc_loss\n",
        "\n",
        "            # Update generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            total_gen_loss_tensor.backward()\n",
        "            generator_optimizer.step()\n",
        "\n",
        "            total_gen_loss += total_gen_loss_tensor.item()\n",
        "\n",
        "            batches += 1\n",
        "\n",
        "            # Print occasional batch updates\n",
        "            if batches % 20 == 0:\n",
        "                print(f\"  Batch {batches}, G Loss: {total_gen_loss_tensor.item():.4f}, \"\n",
        "                      f\"C Loss Real: {critic_loss_real.item():.4f}, \"\n",
        "                      f\"C Loss Fake: {critic_loss_fake.item():.4f}\")\n",
        "\n",
        "        # Calculate average losses for the epoch\n",
        "        avg_gen_loss = total_gen_loss / batches if batches > 0 else float('nan')\n",
        "        avg_critic_loss_real = total_critic_loss_real / (batches * 5) if batches > 0 else float('nan')\n",
        "        avg_critic_loss_fake = total_critic_loss_fake / (batches * 5) if batches > 0 else float('nan')\n",
        "\n",
        "        # Store losses for plotting\n",
        "        gen_losses.append(avg_gen_loss)\n",
        "        critic_losses_real.append(avg_critic_loss_real)\n",
        "        critic_losses_fake.append(avg_critic_loss_fake)\n",
        "\n",
        "        # Print status\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Gen Loss: {avg_gen_loss:.4f}, '\n",
        "              f'Critic Loss Real: {avg_critic_loss_real:.4f}, '\n",
        "              f'Critic Loss Fake: {avg_critic_loss_fake:.4f}, Time: {epoch_time:.2f}s')\n",
        "\n",
        "        # Generate/save/show images every 5 epochs\n",
        "        if (epoch % 5 == 0):\n",
        "            generate_and_save_images(generator, epoch + 1, fixed_noise, checkpoint_dir)\n",
        "\n",
        "            # Create final loss plot\n",
        "            plot_training_losses(gen_losses, critic_losses_real, critic_losses_fake, smoothing_factor=min(128, len(gen_losses)))\n",
        "\n",
        "            \n",
        "        \n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            torch.save({\n",
        "                'generator_state_dict': generator.state_dict(),\n",
        "                'critic_state_dict': critic.state_dict(),\n",
        "                'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n",
        "                'critic_optimizer_state_dict': critic_optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'gen_loss': avg_gen_loss,\n",
        "                'critic_loss_real': avg_critic_loss_real,\n",
        "                'critic_loss_fake': avg_critic_loss_fake\n",
        "            }, os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"Training completed in {total_time:.2f} seconds\")\n",
        "\n",
        "    # Create final loss plot\n",
        "    plot_training_losses(gen_losses, critic_losses_real, critic_losses_fake, smoothing_factor=min(128, len(gen_losses)))\n",
        "\n",
        "    \n",
        "    # Create GIF showing training progress\n",
        "    create_progress_gif(checkpoint_dir)\n",
        "\n",
        "    # Save final models\n",
        "    torch.save(generator, os.path.join(checkpoint_dir, 'Scratch_generator_final.pt'))\n",
        "    torch.save(critic, os.path.join(checkpoint_dir, 'Scratch_critic_final.pt'))\n",
        "    \n",
        "    # Return losses for potential further analysis\n",
        "    return gen_losses, critic_losses_real, critic_losses_fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fKOiZcepHq1N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fKOiZcepHq1N",
        "outputId": "1346cfbd-a29c-44b5-f5d1-a7f52c50687f"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Main Function\n",
        "# ------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Parameters\n",
        "    latent_dim = 256\n",
        "    BATCH_SIZE = 256  # Reduced from 64 to 16 for larger images\n",
        "    GP_WEIGHT = 10.0\n",
        "    EPOCHS = 500\n",
        "    save_interval = 50\n",
        "    checkpoint_dir = '/user/apurvara/Donut 128X128'\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(\"/user/apurvara/Donut_augmented_data.pkl\")  # Update with your path\n",
        "    print(f\"Dataset loaded with shape: {dataset.shape}\")\n",
        "\n",
        "    # Create data loader\n",
        "    wafer_dataset = WaferDataset(dataset)\n",
        "    dataloader = DataLoader(wafer_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "    # Initialize models\n",
        "    feature_extractor = FeatureExtractor().to(device)\n",
        "    feature_extractor.eval()  # Set to evaluation mode since it's not trained\n",
        "\n",
        "    generator = Generator(latent_dim=latent_dim).to(device)\n",
        "    critic = Critic().to(device)\n",
        "\n",
        "    # Initialize optimizers\n",
        "    generator_optimizer = optim.RMSprop(generator.parameters(), lr=5e-5)\n",
        "    critic_optimizer = optim.RMSprop(critic.parameters(), lr=5e-5)\n",
        "\n",
        "    # Print model summaries\n",
        "    print(\"\\nGenerator architecture:\")\n",
        "    print(generator)\n",
        "\n",
        "    print(\"\\nCritic architecture:\")\n",
        "    print(critic)\n",
        "\n",
        "    print(\"\\nFeature Extractor architecture:\")\n",
        "    print(feature_extractor)\n",
        "\n",
        "    # Start training\n",
        "    print(\"\\nStarting training...\")\n",
        "    train(dataloader, generator, critic, feature_extractor, generator_optimizer,\n",
        "          critic_optimizer, EPOCHS, latent_dim, checkpoint_dir, save_interval, GP_WEIGHT)\n",
        "\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "    # Generate samples\n",
        "    print(\"Generating samples...\")\n",
        "    generated_samples = generate_samples(generator, 100, latent_dim, 'generated_samples')\n",
        "\n",
        "    # Save to pickle file\n",
        "    with open('./generated_data.pkl', 'wb') as f:\n",
        "        pickle.dump(generated_samples.numpy(), f)\n",
        "\n",
        "    print(\"Samples generated and saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c85bda",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train(dataloader, generator, critic, feature_extractor, generator_optimizer,\n",
        "          critic_optimizer, epochs, latent_dim, checkpoint_dir, save_interval, GP_WEIGHT, \n",
        "          start_epoch=0, patience=20, min_delta=0.001, device=None):\n",
        "    \"\"\"\n",
        "    Train WGAN with early stopping to prevent overfitting.\n",
        "    \n",
        "    Args:\n",
        "        dataloader: Training data loader\n",
        "        generator: Generator network\n",
        "        critic: Critic network\n",
        "        feature_extractor: Optional feature extractor for perceptual loss\n",
        "        generator_optimizer: Optimizer for generator\n",
        "        critic_optimizer: Optimizer for critic\n",
        "        epochs: Maximum number of epochs to train\n",
        "        latent_dim: Dimension of latent noise vector\n",
        "        checkpoint_dir: Directory to save checkpoints and images\n",
        "        save_interval: Interval (in epochs) to save checkpoints\n",
        "        GP_WEIGHT: Weight for gradient penalty\n",
        "        start_epoch: Epoch to start training from (for resuming)\n",
        "        patience: Number of epochs to wait for improvement before stopping\n",
        "        min_delta: Minimum change to qualify as an improvement\n",
        "        device: Device to use for training (cpu or cuda)\n",
        "    \"\"\"\n",
        "    # Create checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    \n",
        "    # Set device if not specified\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "    # Move models to device\n",
        "    generator = generator.to(device)\n",
        "    critic = critic.to(device)\n",
        "    if feature_extractor is not None:\n",
        "        feature_extractor = feature_extractor.to(device)\n",
        "    \n",
        "    # Create fixed noise vector for visualization\n",
        "    fixed_noise = torch.randn(16, latent_dim, device=device)\n",
        "\n",
        "    # Track losses for plotting\n",
        "    # If resuming training, load previous losses if available\n",
        "    loss_file = os.path.join(checkpoint_dir, 'training_losses.pkl')\n",
        "    if start_epoch > 0 and os.path.exists(loss_file):\n",
        "        print(\"Loading previous training losses...\")\n",
        "        with open(loss_file, 'rb') as f:\n",
        "            losses = pickle.load(f)\n",
        "            gen_losses = losses['gen_losses']\n",
        "            critic_losses_real = losses['critic_losses_real']\n",
        "            critic_losses_fake = losses['critic_losses_fake']\n",
        "    else:\n",
        "        gen_losses = []\n",
        "        critic_losses_real = []\n",
        "        critic_losses_fake = []\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0\n",
        "    best_epoch = 0\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Adjusted Wasserstein distance tracking for convergence\n",
        "    prev_wasserstein_distance = None\n",
        "    convergence_threshold = 0.01  # Threshold for considering model converged\n",
        "    convergence_counter = 0\n",
        "    convergence_patience = 10  # Number of epochs with minimal change to declare convergence\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        # Set models to training mode\n",
        "        generator.train()\n",
        "        critic.train()\n",
        "\n",
        "        # Training phase\n",
        "        total_gen_loss = 0\n",
        "        total_critic_loss_real = 0\n",
        "        total_critic_loss_fake = 0\n",
        "        batches = 0\n",
        "\n",
        "        # Train on batches\n",
        "        for batch_images in dataloader:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_size = batch_images.size(0)\n",
        "\n",
        "            # Train critic multiple times\n",
        "            for _ in range(5):\n",
        "                # Zero gradients\n",
        "                critic_optimizer.zero_grad()\n",
        "                \n",
        "                # Generate latent vectors and fake images\n",
        "                noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "                fake_images = generator(noise)\n",
        "                \n",
        "                # Get critic scores\n",
        "                real_scores = critic(batch_images)\n",
        "                fake_scores = critic(fake_images.detach())\n",
        "                \n",
        "                # Track separate losses\n",
        "                critic_loss_real = -torch.mean(real_scores)\n",
        "                critic_loss_fake = torch.mean(fake_scores)\n",
        "                \n",
        "                # Calculate Wasserstein loss\n",
        "                critic_loss = critic_loss_fake + critic_loss_real\n",
        "                \n",
        "                # Add gradient penalty\n",
        "                gp = gradient_penalty(critic, batch_images, fake_images.detach())\n",
        "                total_critic_loss = critic_loss + GP_WEIGHT * gp\n",
        "                \n",
        "                # Update critic weights\n",
        "                total_critic_loss.backward()\n",
        "                critic_optimizer.step()\n",
        "                \n",
        "                # Accumulate losses for averaging\n",
        "                total_critic_loss_real += critic_loss_real.item()\n",
        "                total_critic_loss_fake += critic_loss_fake.item()\n",
        "\n",
        "            # Train generator\n",
        "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            # Calculate perceptual loss if feature extractor is provided\n",
        "            if feature_extractor is not None:\n",
        "                perc_loss = 0.1 * perceptual_loss(feature_extractor, batch_images, fake_images)\n",
        "            else:\n",
        "                perc_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # Get fake scores from critic\n",
        "            fake_scores = critic(fake_images)\n",
        "\n",
        "            # Calculate generator loss\n",
        "            adv_loss = -torch.mean(fake_scores)\n",
        "            total_gen_loss_tensor = adv_loss + perc_loss\n",
        "\n",
        "            # Update generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            total_gen_loss_tensor.backward()\n",
        "            generator_optimizer.step()\n",
        "\n",
        "            total_gen_loss += total_gen_loss_tensor.item()\n",
        "\n",
        "            batches += 1\n",
        "\n",
        "            # Print occasional batch updates\n",
        "            if batches % 20 == 0:\n",
        "                print(f\"  Batch {batches}, \"\n",
        "                      f\"G Loss: {total_gen_loss_tensor.item():.4f}, \"\n",
        "                      f\"C Loss Real: {critic_loss_real.item():.4f}, \"\n",
        "                      f\"C Loss Fake: {critic_loss_fake.item():.4f}\")\n",
        "\n",
        "        # Calculate average training losses\n",
        "        avg_gen_loss = total_gen_loss / batches if batches > 0 else float('nan')\n",
        "        avg_critic_loss_real = total_critic_loss_real / (batches * 5) if batches > 0 else float('nan')\n",
        "        avg_critic_loss_fake = total_critic_loss_fake / (batches * 5) if batches > 0 else float('nan')\n",
        "\n",
        "        # Store training losses for plotting\n",
        "        gen_losses.append(avg_gen_loss)\n",
        "        critic_losses_real.append(avg_critic_loss_real)\n",
        "        critic_losses_fake.append(avg_critic_loss_fake)\n",
        "        \n",
        "        # Calculate Wasserstein distance\n",
        "        wasserstein_distance = avg_critic_loss_fake - avg_critic_loss_real\n",
        "        \n",
        "        # Check for convergence\n",
        "        if prev_wasserstein_distance is not None:\n",
        "            delta_wd = abs(wasserstein_distance - prev_wasserstein_distance)\n",
        "            if delta_wd < convergence_threshold:\n",
        "                convergence_counter += 1\n",
        "                if convergence_counter >= convergence_patience:\n",
        "                    print(f\"\\nModel converged at epoch {epoch+1}! Wasserstein distance stable for {convergence_patience} epochs.\")\n",
        "                    break\n",
        "            else:\n",
        "                convergence_counter = 0\n",
        "        \n",
        "        prev_wasserstein_distance = wasserstein_distance\n",
        "        \n",
        "        # Print status\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f'Epoch {epoch+1}/{epochs}:')\n",
        "        print(f'  Train - Gen: {avg_gen_loss:.4f}, Critic Real: {avg_critic_loss_real:.4f}, '\n",
        "              f'Critic Fake: {avg_critic_loss_fake:.4f}')\n",
        "        print(f'  Wasserstein Distance: {wasserstein_distance:.4f}, Convergence Counter: {convergence_counter}/{convergence_patience}')\n",
        "        print(f'  Time: {epoch_time:.2f}s')\n",
        "        \n",
        "        # Generate/save/show images periodically\n",
        "        if (epoch % 5 == 0) or (epoch == epochs - 1):\n",
        "            generate_and_save_images(generator, epoch + 1, fixed_noise, checkpoint_dir)\n",
        "        \n",
        "        # Plot losses\n",
        "        plot_training_losses(\n",
        "            gen_losses, critic_losses_real, critic_losses_fake,\n",
        "            smoothing_factor=min(128, len(gen_losses))\n",
        "        )\n",
        "        \n",
        "        # Save current losses\n",
        "        losses = {\n",
        "            'gen_losses': gen_losses,\n",
        "            'critic_losses_real': critic_losses_real,\n",
        "            'critic_losses_fake': critic_losses_fake\n",
        "        }\n",
        "        with open(os.path.join(checkpoint_dir, 'training_losses.pkl'), 'wb') as f:\n",
        "            pickle.dump(losses, f)\n",
        "        \n",
        "        # Apply early stopping based on Wasserstein distance stability\n",
        "        current_val_loss = abs(wasserstein_distance)\n",
        "        \n",
        "        # Check if loss improved\n",
        "        if current_val_loss < best_val_loss - min_delta:\n",
        "            best_val_loss = current_val_loss\n",
        "            counter = 0\n",
        "            best_epoch = epoch\n",
        "            \n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'generator_state_dict': generator.state_dict(),\n",
        "                'critic_state_dict': critic.state_dict(),\n",
        "                'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n",
        "                'critic_optimizer_state_dict': critic_optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'best_val_loss': best_val_loss\n",
        "            }, os.path.join(checkpoint_dir, 'best_model.pt'))\n",
        "            \n",
        "            print(f\"  ✓ Wasserstein distance improved to {best_val_loss:.6f} - Saved best model\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"  ✗ No improvement in Wasserstein distance for {counter} epochs. \"\n",
        "                  f\"Best: {best_val_loss:.6f} at epoch {best_epoch+1}\")\n",
        "        \n",
        "        # Check if we should stop early\n",
        "        if counter >= patience:\n",
        "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs!\")\n",
        "            print(f\"Best model was at epoch {best_epoch+1} with Wasserstein distance {best_val_loss:.6f}\")\n",
        "            break\n",
        "            \n",
        "        # Regular checkpoint saving\n",
        "        if (epoch + 1) % save_interval == 0 or (epoch == epochs - 1):\n",
        "            torch.save({\n",
        "                'generator_state_dict': generator.state_dict(),\n",
        "                'critic_state_dict': critic.state_dict(),\n",
        "                'generator_optimizer_state_dict': generator_optimizer.state_dict(),\n",
        "                'critic_optimizer_state_dict': critic_optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'gen_loss': avg_gen_loss,\n",
        "                'critic_loss_real': avg_critic_loss_real,\n",
        "                'critic_loss_fake': avg_critic_loss_fake\n",
        "            }, os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"Training completed in {total_time:.2f} seconds\")\n",
        "    \n",
        "    # Create final loss plot\n",
        "    plot_training_losses(\n",
        "        gen_losses, critic_losses_real, critic_losses_fake,\n",
        "        smoothing_factor=min(128, len(gen_losses))\n",
        "    )\n",
        "\n",
        "    # Create GIF showing training progress\n",
        "    create_progress_gif(checkpoint_dir)\n",
        "    \n",
        "    # Load the best model before returning\n",
        "    best_checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_model.pt'))\n",
        "    generator.load_state_dict(best_checkpoint['generator_state_dict'])\n",
        "    critic.load_state_dict(best_checkpoint['critic_state_dict'])\n",
        "    \n",
        "    # Save final models (best versions)\n",
        "    torch.save(generator, os.path.join(checkpoint_dir, 'Scratch_generator_final.pt'))\n",
        "    torch.save(critic, os.path.join(checkpoint_dir, 'Scratch_critic_final.pt'))\n",
        "    \n",
        "    return gen_losses, critic_losses_real, critic_losses_fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a997ee12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------ \n",
        "# Main Function for Resuming Training \n",
        "# ------------------------------ \n",
        "if __name__ == \"__main__\":\n",
        "    # Parameters\n",
        "    latent_dim = 256\n",
        "    BATCH_SIZE = 256  \n",
        "    GP_WEIGHT = 10.0\n",
        "    ADDITIONAL_EPOCHS = 1000  # Train for 500 more epochs (total will be 1000)\n",
        "    save_interval = 50\n",
        "    checkpoint_dir = '/user/apurvara/Donut 128X128'\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # Create checkpoint directory\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    \n",
        "    # Load dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(\"/user/apurvara/Donut_augmented_data.pkl\")\n",
        "    print(f\"Dataset loaded with shape: {dataset.shape}\")\n",
        "    \n",
        "    # Create data loader\n",
        "    wafer_dataset = WaferDataset(dataset)\n",
        "    dataloader = DataLoader(wafer_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    \n",
        "    # Initialize models\n",
        "    feature_extractor = FeatureExtractor().to(device)\n",
        "    feature_extractor.eval()  # Set to evaluation mode since it's not trained\n",
        "    \n",
        "    generator = Generator(latent_dim=latent_dim).to(device)\n",
        "    critic = Critic().to(device)\n",
        "    \n",
        "    # Initialize optimizers with lower learning rate for better convergence\n",
        "    generator_optimizer = optim.RMSprop(generator.parameters(), lr=1e-5)  # Reduced from 5e-5\n",
        "    critic_optimizer = optim.RMSprop(critic.parameters(), lr=1e-5)  # Reduced from 5e-5\n",
        "    \n",
        "    # Find the latest checkpoint\n",
        "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_')]\n",
        "    if checkpoint_files:\n",
        "        # Extract epoch numbers from filenames\n",
        "        epoch_numbers = [int(f.split('_')[-1].split('.')[0]) for f in checkpoint_files]\n",
        "        latest_epoch = max(epoch_numbers)\n",
        "        latest_checkpoint = f'checkpoint_epoch_{latest_epoch}.pt'\n",
        "        latest_checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
        "        \n",
        "        print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
        "        checkpoint = torch.load(latest_checkpoint_path, map_location=device)\n",
        "        \n",
        "        # Load model states\n",
        "        generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "        critic.load_state_dict(checkpoint['critic_state_dict'])\n",
        "        \n",
        "        # Load optimizer states\n",
        "        generator_optimizer.load_state_dict(checkpoint['generator_optimizer_state_dict'])\n",
        "        critic_optimizer.load_state_dict(checkpoint['critic_optimizer_state_dict'])\n",
        "        \n",
        "        # Update learning rates in the loaded optimizer states\n",
        "        for param_group in generator_optimizer.param_groups:\n",
        "            param_group['lr'] = 1e-5\n",
        "        \n",
        "        for param_group in critic_optimizer.param_groups:\n",
        "            param_group['lr'] = 1e-5\n",
        "        \n",
        "        # Get the starting epoch\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print(\"No checkpoint found. Starting from scratch.\")\n",
        "    \n",
        "    print(\"\\nGenerator architecture:\")\n",
        "    print(generator)\n",
        "    \n",
        "    print(\"\\nCritic architecture:\")\n",
        "    print(critic)\n",
        "    \n",
        "    print(\"\\nFeature Extractor architecture:\")\n",
        "    print(feature_extractor)\n",
        "    \n",
        "    # Start training\n",
        "    print(\"\\nStarting/Resuming training...\")\n",
        "    \n",
        "    # Set convergence parameters\n",
        "    patience = 30  # Increased patience for a more thorough assessment\n",
        "    min_delta = 0.001  # Minimum improvement threshold\n",
        "    \n",
        "    train(dataloader=dataloader, \n",
        "          generator=generator, \n",
        "          critic=critic, \n",
        "          feature_extractor=feature_extractor, \n",
        "          generator_optimizer=generator_optimizer,\n",
        "          critic_optimizer=critic_optimizer, \n",
        "          epochs=start_epoch + ADDITIONAL_EPOCHS, \n",
        "          latent_dim=latent_dim, \n",
        "          checkpoint_dir=checkpoint_dir, \n",
        "          save_interval=save_interval, \n",
        "          GP_WEIGHT=GP_WEIGHT, \n",
        "          start_epoch=start_epoch,\n",
        "          patience=patience,\n",
        "          min_delta=min_delta,\n",
        "          device=device)\n",
        "    \n",
        "    print(\"Training completed successfully!\")\n",
        "    \n",
        "    # Generate samples\n",
        "    print(\"Generating samples...\")\n",
        "    generated_samples = generate_samples(generator, 100, latent_dim, 'generated_samples', device)\n",
        "    \n",
        "    # Save to pickle file\n",
        "    with open('./generated_data.pkl', 'wb') as f:\n",
        "        pickle.dump(generated_samples.numpy(), f)\n",
        "    \n",
        "    print(\"Samples generated and saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ce2e26",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_samples_from_best_model(checkpoint_dir, output_dir, num_images=100, latent_dim=256, device=None):\n",
        "    \"\"\"\n",
        "    Generate samples using the best model saved during training.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_dir: Directory containing model checkpoints\n",
        "        output_dir: Directory to save generated samples\n",
        "        num_images: Number of images to generate\n",
        "        latent_dim: Dimension of latent noise vector\n",
        "        device: Device to use for inference\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    \n",
        "    # Load the best model\n",
        "    best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
        "    if os.path.exists(best_model_path):\n",
        "        print(f\"Loading best model from {best_model_path}\")\n",
        "        checkpoint = torch.load(best_model_path, map_location=device)\n",
        "        \n",
        "        # Initialize generator\n",
        "        generator = Generator(latent_dim=latent_dim).to(device)\n",
        "        \n",
        "        # Load weights\n",
        "        generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "        \n",
        "        # Set to evaluation mode\n",
        "        generator.eval()\n",
        "        \n",
        "        # Generate in batches\n",
        "        batch_size = 16\n",
        "        all_images = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for i in range(0, num_images, batch_size):\n",
        "                batch_count = min(batch_size, num_images - i)\n",
        "                noise = torch.randn(batch_count, latent_dim, device=device)\n",
        "                images = generator(noise)\n",
        "                all_images.append(images.cpu())\n",
        "        \n",
        "        # Concatenate all batches\n",
        "        all_images = torch.cat(all_images, dim=0)\n",
        "        \n",
        "        # Plot a grid of generated images\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        for i in range(min(25, num_images)):\n",
        "            plt.subplot(5, 5, i+1)\n",
        "            # Adjust based on your image format\n",
        "            plt.imshow(all_images[i, 0, :, :].numpy(), cmap='brg')\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_dir}/best_model_samples_grid.png', dpi=300)\n",
        "        plt.show()\n",
        "        \n",
        "        # Save individual images\n",
        "        for i in range(min(100, num_images)):\n",
        "            img = all_images[i, 0, :, :].numpy()\n",
        "            plt.figure(figsize=(3, 3))\n",
        "            plt.imshow(img, cmap='brg')\n",
        "            plt.axis('off')\n",
        "            plt.savefig(f'{output_dir}/sample_{i+1}.png', dpi=150)\n",
        "            plt.close()\n",
        "        \n",
        "        # Save as pickle file\n",
        "        with open(f'{output_dir}/best_model_samples.pkl', 'wb') as f:\n",
        "            pickle.dump(all_images.numpy(), f)\n",
        "        \n",
        "        print(f\"Generated {num_images} samples from the best model and saved to {output_dir}\")\n",
        "        return all_images\n",
        "    else:\n",
        "        print(\"Error: Best model checkpoint not found!\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd282ecf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# After training is complete, generate samples from the best model\n",
        "print(\"Generating samples from the best model...\")\n",
        "output_dir = 'best_model_samples'\n",
        "best_samples = generate_samples_from_best_model(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    output_dir=output_dir,\n",
        "    num_images=200,\n",
        "    latent_dim=latent_dim,\n",
        "    device=device\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "32Be4BXthRMH"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
